## Instructions
+ Set up virtual environment or environment of choice and install requirements.txt
+ Please navigate to scripts folder and run scripts from cmd in following order
  + pull_data.py
    + Will grab csv files from external github repository
    + Print shape of df if loaded correctly
  + train_model.py
    + Will save a classification report to cwd
    + Saves a pipeline for RF model as pickle file on cwd
  + score_model.py
    + Loads pickle file 
    + Saves a prediction array to csv

## EDA Notebook file
+ Notebook contains all exploratory data analysis
+ Contains testing for several models
+ If file doesn't load please view on [nbviewer](https://nbviewer.jupyter.org/github/justinherman42/Data_Science_Projects/blob/a730cc88911ab89f4f13615f96e8ee3e66a2e63d/Python/Titanic_Survival_Pipeline/eda.ipynb)






